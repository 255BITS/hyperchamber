{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hyperchamber as hc\n",
    "from shared.ops import *\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "learning_rates = [1, 0.75, 0.5, 0.25]\n",
    "hc.set(\"learning_rate\", learning_rates)\n",
    "hidden_layers = [ [], [26], [128], [16, 32] ]\n",
    "hc.permute.set(\"hidden_layer\", hidden_layers)\n",
    "\n",
    "hc.set(\"batch_size\", 128)\n",
    "\n",
    "X_DIMS=[28,28]\n",
    "Y_DIMS=10\n",
    "\n",
    "#def validate(value):\n",
    "#    return value != value #NaN\n",
    "\n",
    "#hc.evolve.evolve(\"learn_rate\", 0.2, validate)\n",
    "\n",
    "def hidden_layers(config, x):\n",
    "    output = tf.reshape(x, [config[\"batch_size\"], X_DIMS[0]*X_DIMS[1]])\n",
    "    for i, layer in enumerate(config['hidden_layer']):\n",
    "        output = linear(output, layer, scope=\"l\"+str(i))\n",
    "        output = tf.nn.tanh(output)\n",
    "    return output\n",
    "\n",
    "def output_layer(config, x):\n",
    "    return linear(x, Y_DIMS)\n",
    "\n",
    "def create(config):\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    x = tf.placeholder(tf.float32, [batch_size, X_DIMS[0], X_DIMS[1], 1], name=\"x\")\n",
    "    y = tf.placeholder(tf.float32, [batch_size, Y_DIMS], name=\"y\")\n",
    "\n",
    "    hidden = hidden_layers(config, x)\n",
    "    output = output_layer(config, hidden)\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output, y), name=\"loss\")\n",
    "\n",
    "    output = tf.nn.softmax(output)\n",
    "    correct_prediction = tf.equal(tf.argmax(output,1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    variables = tf.trainable_variables()\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(config['learning_rate']).minimize(loss)\n",
    "\n",
    "\n",
    "    set_tensor(\"x\", x)\n",
    "    set_tensor(\"y\", y)\n",
    "    set_tensor(\"loss\", loss)\n",
    "    set_tensor(\"optimizer\", optimizer)\n",
    "    set_tensor(\"accuracy\", accuracy)\n",
    "    \n",
    "def train(sess, config, x_input, y_labels):\n",
    "    x = get_tensor(\"x\")\n",
    "    y = get_tensor(\"y\")\n",
    "    cost = get_tensor(\"loss\")\n",
    "    optimizer = get_tensor(\"optimizer\")\n",
    "    accuracy = get_tensor(\"accuracy\")\n",
    "\n",
    "    _, accuracy, cost = sess.run([optimizer, accuracy, cost], feed_dict={x:x_input, y:y_labels})\n",
    "\n",
    "\n",
    "    #hc.cost(config, cost)\n",
    "    #print(\"Accuracy %.2f Cost %.2f\" % (accuracy, cost))\n",
    "\n",
    "def test(sess, config, x_input, y_labels):\n",
    "    x = get_tensor(\"x\")\n",
    "    y = get_tensor(\"y\")\n",
    "    cost = get_tensor(\"loss\")\n",
    "    accuracy = get_tensor(\"accuracy\")\n",
    "\n",
    "    accuracy, cost = sess.run([accuracy, cost], feed_dict={x:x_input, y:y_labels})\n",
    "\n",
    "\n",
    "    print(\"Accuracy %.2f Cost %.2f\" % (accuracy, cost))\n",
    "    return accuracy, cost\n",
    "\n",
    "\n",
    "def epoch(sess, config):\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    n_samples = mnist.train.num_examples\n",
    "    total_batch = int(n_samples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        x, y = mnist.train.next_batch(batch_size)\n",
    "        x=np.reshape(x, [batch_size, X_DIMS[0], X_DIMS[1], 1])\n",
    "        train(sess, config, x, y)\n",
    "\n",
    "def test_config(sess, config):\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    n_samples = mnist.test.num_examples\n",
    "    total_batch = int(n_samples / batch_size)\n",
    "    accuracies = []\n",
    "    costs = []\n",
    "    for i in range(total_batch):\n",
    "        x, y = mnist.test.next_batch(batch_size)\n",
    "        x=np.reshape(x, [batch_size, X_DIMS[0], X_DIMS[1], 1])\n",
    "        accuracy, cost = test(sess, config, x, y)\n",
    "        accuracies.append(accuracy)\n",
    "        costs.append(cost)\n",
    "    return accuracies, costs\n",
    "\n",
    "\n",
    "for config in hc.configs(100):\n",
    "    print(\"Testing configuration\", config)\n",
    "    sess = tf.Session()\n",
    "    graph = create(config)\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)\n",
    "    for i in range(10):\n",
    "        epoch(sess, config)\n",
    "    accuracies, costs = test_config(sess, config)\n",
    "    accuracy, cost = np.mean(accuracies), np.mean(costs)\n",
    "    results =  {\n",
    "        'accuracy':accuracy,\n",
    "        'cost':cost\n",
    "        }\n",
    "    hc.record(config, results)\n",
    "    ops.reset_default_graph()\n",
    "    sess.close()\n",
    "\n",
    "\n",
    "def by_accuracy(x):\n",
    "    config,result = x\n",
    "    return 1-result['accuracy']\n",
    "\n",
    "for config, result in hc.top(by_accuracy):\n",
    "    print(\"RESULTS\")\n",
    "    print(config, result)\n",
    "    \n",
    "\n",
    "\n",
    "    #print(\"Done testing.  Final cost was:\", hc.cost())\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "#for gold, silver, bronze in hc.top_configs(3):"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
